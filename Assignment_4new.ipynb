{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from random import randint\n",
    "import random\n",
    "\n",
    "ROWS      = 5\n",
    "COLUMNS   = 7\n",
    "WALL_SIZE = 7\n",
    "ACTIONS   = 4\n",
    "STATES    = ROWS*COLUMNS \n",
    "NEXT_STATES = 4\n",
    "γ         = 0.9  # γάμμα\n",
    "\n",
    "# This is my world\n",
    "M =([0,  0,  0, 0, 0,  0, 0],\n",
    "    [0,  1, -1, 0, 0,  0, 0],\n",
    "    [0, -1, -1, 0, 0,  0, 0],\n",
    "    [0,  0, -1, 0, 0, -1, 0],\n",
    "    [0,  0,  0, 0, 1, -1, 2])\n",
    "\n",
    "# Actions\n",
    "A=[\"E\", \"W\", \"N\",\"S\"] # East, West, North, South\n",
    "\n",
    "# States\n",
    "S = ((0, 0), (0, 1), (0, 2), (0, 3), (0, 4), (0, 5), (0, 6),\n",
    "     (1, 0), (1, 1), (1, 2), (1, 3), (1, 4), (1, 5), (1, 6),\n",
    "     (2, 0), (2, 1), (2, 2), (2, 3), (2, 4), (2, 5), (2, 6),\n",
    "     (3, 0), (3, 1), (3, 2), (3, 3), (3, 4), (3, 5), (3, 6),\n",
    "     (4, 0), (4, 1), (4, 2), (4, 3), (4, 4), (4, 5), (4, 6),\n",
    "     )\n",
    "\n",
    "# Start and Goal\n",
    "starting_state = S[8]\n",
    "goal_state     = S[34]\n",
    "\n",
    "# Wall \n",
    "W=((1, 2), (2, 1), (2, 2), (2, 1), (3, 2), (3, 5), (4, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def ConvertIndexToTuple(state):\n",
    "    return(tuple(int(x) for x in np.base_repr(state, 7, 1)[-2::]))\n",
    "\n",
    "def ConvertTupleToIndex(state):\n",
    "    return(int(\"\".join(str(x) for x in state), 7))\n",
    "\n",
    "def getNextState(state, action):\n",
    "    # Check if we reached goal state\n",
    "    if state == goal_state:\n",
    "        return state\n",
    "    \n",
    "    if action == \"E\":\n",
    "        next_state_index=ConvertTupleToIndex(state)+1\n",
    "    elif action == \"W\":\n",
    "        next_state_index=ConvertTupleToIndex(state)-1 \n",
    "    elif action == \"N\":\n",
    "        next_state_index=ConvertTupleToIndex(state)-COLUMNS\n",
    "    elif action == \"S\":\n",
    "        next_state_index=ConvertTupleToIndex(state)+COLUMNS \n",
    "             \n",
    "    # Check if next state hits the wall.\n",
    "    for i in range(0,WALL_SIZE):\n",
    "        if next_state_index == ConvertTupleToIndex(W[i]):\n",
    "            return state\n",
    "            \n",
    "    # Check if next state is within Maze.\n",
    "    if next_state_index >=0 and next_state_index <=34:\n",
    "        next_state=ConvertIndexToTuple(next_state_index)\n",
    "        return next_state\n",
    "    else:\n",
    "        return state  \n",
    "    \n",
    "def getPossibleStates(state, action):\n",
    "    next_states = [0 for x in range(NEXT_STATES)]\n",
    "    next_states_index = [0 for x in range(NEXT_STATES)]\n",
    "    \n",
    "    for i in range(NEXT_STATES):\n",
    "        next_states[i]=state\n",
    "    \n",
    "    # Check if we reached goal state\n",
    "    if state == goal_state:\n",
    "        return next_states\n",
    "    \n",
    "    next_states_index[0]=ConvertTupleToIndex(state)+1 # E\n",
    "    next_states_index[1]=ConvertTupleToIndex(state)-1 # W\n",
    "    next_states_index[2]=ConvertTupleToIndex(state)-COLUMNS # N\n",
    "    next_states_index[3]=ConvertTupleToIndex(state)+COLUMNS # S\n",
    "             \n",
    "    # Check if next state hits the wall.\n",
    "    for i in range(0,NEXT_STATES):\n",
    "        for j in range(0,WALL_SIZE):\n",
    "            if next_states_index[i] == ConvertTupleToIndex(W[j]):\n",
    "                next_states_index[i]=ConvertTupleToIndex(state)\n",
    "\n",
    "        # Check if next state is within Maze.\n",
    "        if next_states_index[i] <0 or next_states_index[i] >34:\n",
    "            next_states_index[i]=ConvertTupleToIndex(state)\n",
    "\n",
    "        next_states[i]=ConvertIndexToTuple(next_states_index[i])\n",
    " \n",
    "    return next_states\n",
    "def AllStatesTransition(current_state, action):\n",
    "    next_states_probability = [0 for x in range(NEXT_STATES)]\n",
    "    \n",
    "    for i in range(0,NEXT_STATES):\n",
    "        next_states_probability[i]=0\n",
    "    \n",
    "    if action == \"E\":\n",
    "        next_states_probability[0] = 0.7\n",
    "    elif action == \"W\":\n",
    "        next_states_probability[1] = 0.7\n",
    "    elif action == \"N\":\n",
    "        next_states_probability[2] = 0.7\n",
    "    elif action == \"S\":\n",
    "        next_states_probability[3] = 0.7 \n",
    "    \n",
    "    for i in range(0,NEXT_STATES):\n",
    "        if next_states_probability[i]==0:\n",
    "            next_states_probability[i]=0.1\n",
    "    return next_states_probability        \n",
    "\n",
    "def getReward( action, next_states):\n",
    "    next_states_reward = [0 for x in range(NEXT_STATES)]\n",
    "    \n",
    "    for i in range(0,NEXT_STATES):\n",
    "        if next_states[i] == goal_state:\n",
    "            next_states_reward[i]=10\n",
    "        else:\n",
    "            next_states_reward[i]=0\n",
    "    return next_states_reward  \n",
    "\n",
    "def getSingleStateReward( action, next_state):\n",
    "    next_state_reward =0\n",
    "    \n",
    "    if next_state == goal_state:\n",
    "        next_state_reward=10\n",
    "    else:\n",
    "        next_state_reward=0\n",
    "\n",
    "    return next_state_reward   \n",
    "\n",
    "def StateTransition(current_state, action, next_state):\n",
    "    #next_state = getNextState( current_state, action) \n",
    "    if current_state == next_state:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0.7\n",
    "\n",
    "# Might need it.\n",
    "def weighted_choice(weights):\n",
    "    totals = []\n",
    "    running_total = 0\n",
    "\n",
    "    for w in weights:\n",
    "        running_total += w\n",
    "        totals.append(running_total)\n",
    "\n",
    "    rnd = random.random() * running_total\n",
    "    for i, total in enumerate(totals):\n",
    "        if rnd < total:\n",
    "            return i     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def PolicyEvaluation(P,R,V,π,γ):\n",
    "    Δ=0\n",
    "    θ=2\n",
    "    while Δ<θ:\n",
    "        for s in range (0, STATES):\n",
    "            v=V[s]\n",
    "            for a in range (0, ACTIONS):\n",
    "                for n in range (0, NEXT_STATES):\n",
    "                    V[s]+=π[s][a]*P[s][a][n] * (R[s][a][n]+ γ*V[n])\n",
    "                    Δ=max(Δ, abs(v-V[s]))\n",
    "        return V\n",
    "\n",
    "def PolicyImprovement(P,R,V,π,γ):\n",
    "    policy_stable=True\n",
    "    for s in range (0, STATES):\n",
    "        for a in range (0, ACTIONS):\n",
    "            b=π[s][a]\n",
    "            temp=[0 for x in range(NEXT_STATES)]\n",
    "            for n in range (0, NEXT_STATES):\n",
    "                temp[n]+=P[s][a][n] * (R[s][a][n]+ γ*V[n])\n",
    "                #np.argmax()\n",
    "            max_index_action= np.argmax(temp)      \n",
    "            π[s][a]= temp[max_index_action]\n",
    "            if b!=π[s][a]:\n",
    "                policy_stable=False\n",
    "    return policy_stable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define P and R and N matrices.\n",
    "\n",
    "R = [[[0 for z in range(NEXT_STATES)] for x in range(ACTIONS)] for y in range(STATES)]  # Reward\n",
    "N = [[[0 for z in range(NEXT_STATES)] for x in range(ACTIONS)] for y in range(STATES)]  # Next State\n",
    "P = [[[0 for z in range(NEXT_STATES)] for x in range(ACTIONS)] for y in range(STATES)]  # Probabilty_new\n",
    "\n",
    "# Initialize P, R and N\n",
    "for i in range (0, STATES):\n",
    "    for j in range (0, ACTIONS):\n",
    "        current_state = S[i]\n",
    "        action = A[j]\n",
    "        next_states = getPossibleStates(current_state, action)\n",
    "        N[i][j] = next_states\n",
    "        P[i][j] = AllStatesTransition(current_state, action)\n",
    "        R[i][j] = getReward( action, next_states)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7 [[0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0], [1.0, 1.0, 1.0, 7.0], [0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0], [7.0, 1.0, 1.0, 1.0], [7.0, 7.0, 7.0, 7.0]] \n",
      "\n",
      " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.5, 0.0, 0.0, 0.0, 0.0, 0.0, 2.5, 10.0] \n",
      " False \n",
      "\n",
      "0.7 [[0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0], [1.0, 1.0, 1.0, 7.0], [0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0], [7.0, 1.0, 1.0, 1.0], [7.0, 7.0, 7.0, 7.0]] \n",
      "\n",
      " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 54.49999999999999, 0.0, 0.0, 0.0, 0.0, 0.0, 54.49999999999999, 290.0] \n",
      " True \n",
      "\n",
      "0.7 [[0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0], [1.0, 1.0, 1.0, 7.0], [0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0], [7.0, 1.0, 1.0, 1.0], [7.0, 7.0, 7.0, 7.0]] \n",
      "\n",
      " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 54.49999999999999, 0.0, 0.0, 0.0, 0.0, 0.0, 54.49999999999999, 290.0] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize V(s)=0 and Q\n",
    "V = [0 for x in range(STATES)] \n",
    "Q = [[0 for x in range(ACTIONS)] for y in range(STATES)] \n",
    "\n",
    "# Initialize π(s,α)=0.25\n",
    "π = [[0.25 for x in range(ACTIONS)] for y in range(STATES)]  \n",
    "\n",
    "# change gamma\n",
    "γ=0.7\n",
    "\n",
    "stability=True\n",
    "total_reward_vf=0\n",
    "\n",
    "V=PolicyEvaluation(P,R,V,π,γ)\n",
    "stability=PolicyImprovement(P,R,V,π,γ)\n",
    "print(γ,π, \"\\n\\n\", V,\"\\n\", stability,\"\\n\")\n",
    "\n",
    "# for i in range (0,10):\n",
    "#     V=PolicyEvaluation(P,R,V,π,γ)\n",
    "#     stability=PolicyImprovement(P,R,V,π,γ)\n",
    "    \n",
    "# Policy Iteration Algo\n",
    "while stability == False:\n",
    "    V=PolicyEvaluation(P,R,V,π,γ)\n",
    "    stability=PolicyImprovement(P,R,V,π,γ)\n",
    "    print(γ,π, \"\\n\\n\", V,\"\\n\", stability,\"\\n\")\n",
    "    \n",
    "\n",
    "print(γ,π, \"\\n\\n\", V,\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ε-greedy selection\n",
    "def selectActionGreedy(AS, AS_ind,Q, s_ind, step):   \n",
    "    \n",
    "    if step <= STEPS_GR:\n",
    "        max_ind=np.argmax(Q[s_ind])\n",
    "        AS[s_ind]=A[max_ind] \n",
    "        AS_ind[s_ind]=max_ind\n",
    "    else:\n",
    "        AS_ind[s_ind]=randint(0,3)\n",
    "        AS[s_ind]=A[AS_ind[s_ind]]\n",
    "\n",
    "    return AS[s_ind]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 6) 74 [[0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0], [0, 0.0, 0.0, 0.0], [0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0], [0, 0, 0, 0], [0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0], [0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0], [0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0.0, 0], [0.0, 0, 0, 0.0], [0, 0.0, 0.0, 0.0], [0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0], [0.0, 0.0, 0, 4.0], [0, 0, 0.0, 0.0], [0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0], [0, 8.505600000000001, 4.0, 0]]\n",
      "40\n"
     ]
    }
   ],
   "source": [
    "# ε-greedy params\n",
    "ε=0.1\n",
    "STATES_GR = int (STATES *(1-ε))\n",
    "STATES_RAND=STATES-STATES_GR\n",
    "\n",
    "STEPS=100\n",
    "STEPS_GR = int (STEPS *(1-ε))\n",
    "STEPS_RAND=STEPS-STEPS_GR\n",
    "# A[randint(0,3)] # Random Policy\n",
    "    \n",
    "# Initialize V(s)=0\n",
    "V = [0 for x in range(STATES)] \n",
    "Q = [[0 for x in range(ACTIONS)] for y in range(STATES)] \n",
    "\n",
    "#Learning rate\n",
    "α=0.4\n",
    "\n",
    "# Initialize array to hold the selected actions\n",
    "AS = [0 for x in range(STATES)]\n",
    "AS_ind = [0 for x in range(STATES)]\n",
    "\n",
    "total_reward=0  \n",
    "\n",
    "# # ε-greedy selection\n",
    "# for s in range (0, STATES_GR):\n",
    "#     max_ind=np.argmax(Q[s])\n",
    "#     AS[s]=A[max_ind] \n",
    "#     AS_ind[s]=max_ind\n",
    "# for s in range (STATES_GR, STATES):\n",
    "#     AS_ind[s]=randint(0,3)\n",
    "#     AS[s]=A[AS_ind[s]]      \n",
    "\n",
    "# Q-learning Algorithm\n",
    "for ep in range (0, 100):\n",
    "    s=starting_state\n",
    "    for step in range (0, STEPS):\n",
    "        s_ind=ConvertTupleToIndex(s)\n",
    "        a=selectActionGreedy(AS, AS_ind, Q, s_ind,step)\n",
    "        s_n=getNextState(s,a)\n",
    "        s_n_ind=ConvertTupleToIndex(s_n)\n",
    "        r=getSingleStateReward(a,s_n)\n",
    "        Q[s_ind][AS_ind[s_ind]]+=α*(r+γ*max(Q[s_n_ind])-Q[s_ind][AS_ind[s_ind]])\n",
    "        s=s_n\n",
    "        total_reward+=r # Accumulate Reward\n",
    "    if s==goal_state:\n",
    "        break   \n",
    "\n",
    "print(s, ep, Q)  \n",
    "print(total_reward)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
