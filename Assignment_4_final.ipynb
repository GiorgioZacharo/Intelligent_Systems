{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from random import randint\n",
    "import random\n",
    "\n",
    "ROWS      = 5\n",
    "COLUMNS   = 7\n",
    "WALL_SIZE = 7\n",
    "ACTIONS   = 4\n",
    "STATES    = ROWS*COLUMNS \n",
    "NEXT_STATES = 4\n",
    "γ         = 0.9  # γάμμα\n",
    "\n",
    "# This is my world\n",
    "M =([0,  0,  0, 0, 0,  0, 0],\n",
    "    [0,  1, -1, 0, 0,  0, 0],\n",
    "    [0, -1, -1, 0, 0,  0, 0],\n",
    "    [0,  0, -1, 0, 0, -1, 0],\n",
    "    [0,  0,  0, 0, 1, -1, 2])\n",
    "\n",
    "# Actions\n",
    "A=[\"E\", \"W\", \"N\",\"S\"] # East, West, North, South\n",
    "\n",
    "# States\n",
    "S = ((0, 0), (0, 1), (0, 2), (0, 3), (0, 4), (0, 5), (0, 6),\n",
    "     (1, 0), (1, 1), (1, 2), (1, 3), (1, 4), (1, 5), (1, 6),\n",
    "     (2, 0), (2, 1), (2, 2), (2, 3), (2, 4), (2, 5), (2, 6),\n",
    "     (3, 0), (3, 1), (3, 2), (3, 3), (3, 4), (3, 5), (3, 6),\n",
    "     (4, 0), (4, 1), (4, 2), (4, 3), (4, 4), (4, 5), (4, 6),\n",
    "     )\n",
    "\n",
    "# Start and Goal\n",
    "starting_state = S[8]\n",
    "goal_state     = S[34]\n",
    "\n",
    "# Wall \n",
    "W=((1, 2), (2, 1), (2, 2), (2, 1), (3, 2), (3, 5), (4, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def ConvertIndexToTuple(state):\n",
    "    return(tuple(int(x) for x in np.base_repr(state, 7, 1)[-2::]))\n",
    "\n",
    "def ConvertTupleToIndex(state):\n",
    "    return(int(\"\".join(str(x) for x in state), 7))\n",
    "\n",
    "def getNextState(state, action):\n",
    "    # Check if we reached goal state\n",
    "    if state == goal_state:\n",
    "        return state\n",
    "    \n",
    "    if action == \"E\":\n",
    "        next_state_index=ConvertTupleToIndex(state)+1\n",
    "    elif action == \"W\":\n",
    "        next_state_index=ConvertTupleToIndex(state)-1 \n",
    "    elif action == \"N\":\n",
    "        next_state_index=ConvertTupleToIndex(state)-COLUMNS\n",
    "    elif action == \"S\":\n",
    "        next_state_index=ConvertTupleToIndex(state)+COLUMNS \n",
    "             \n",
    "    # Check if next state hits the wall.\n",
    "    for i in range(0,WALL_SIZE):\n",
    "        if next_state_index == ConvertTupleToIndex(W[i]):\n",
    "            return state\n",
    "            \n",
    "    # Check if next state is within Maze.\n",
    "    if next_state_index >=0 and next_state_index <=34:\n",
    "        next_state=ConvertIndexToTuple(next_state_index)\n",
    "        return next_state\n",
    "    else:\n",
    "        return state  \n",
    "    \n",
    "def getPossibleStates(state, action):\n",
    "    next_states = [0 for x in range(NEXT_STATES)]\n",
    "    next_states_index = [0 for x in range(NEXT_STATES)]\n",
    "    \n",
    "    for i in range(NEXT_STATES):\n",
    "        next_states[i]=state\n",
    "    \n",
    "    # Check if we reached goal state\n",
    "    if state == goal_state:\n",
    "        return next_states\n",
    "    \n",
    "    next_states_index[0]=ConvertTupleToIndex(state)+1 # E\n",
    "    next_states_index[1]=ConvertTupleToIndex(state)-1 # W\n",
    "    next_states_index[2]=ConvertTupleToIndex(state)-COLUMNS # N\n",
    "    next_states_index[3]=ConvertTupleToIndex(state)+COLUMNS # S\n",
    "             \n",
    "    # Check if next state hits the wall.\n",
    "    for i in range(0,NEXT_STATES):\n",
    "        for j in range(0,WALL_SIZE):\n",
    "            if next_states_index[i] == ConvertTupleToIndex(W[j]):\n",
    "                next_states_index[i]=ConvertTupleToIndex(state)\n",
    "\n",
    "        # Check if next state is within Maze.\n",
    "        if next_states_index[i] <0 or next_states_index[i] >34:\n",
    "            next_states_index[i]=ConvertTupleToIndex(state)\n",
    "\n",
    "        next_states[i]=ConvertIndexToTuple(next_states_index[i])\n",
    " \n",
    "    return next_states\n",
    "def AllStatesTransition(current_state, action):\n",
    "    next_states_probability = [0 for x in range(NEXT_STATES)]\n",
    "    \n",
    "    for i in range(0,NEXT_STATES):\n",
    "        next_states_probability[i]=0\n",
    "    \n",
    "    if action == \"E\":\n",
    "        next_states_probability[0] = 0.7\n",
    "    elif action == \"W\":\n",
    "        next_states_probability[1] = 0.7\n",
    "    elif action == \"N\":\n",
    "        next_states_probability[2] = 0.7\n",
    "    elif action == \"S\":\n",
    "        next_states_probability[3] = 0.7 \n",
    "    \n",
    "    for i in range(0,NEXT_STATES):\n",
    "        if next_states_probability[i]==0:\n",
    "            next_states_probability[i]=0.1\n",
    "    return next_states_probability        \n",
    "\n",
    "def getReward( action, next_states):\n",
    "    next_states_reward = [0 for x in range(NEXT_STATES)]\n",
    "    \n",
    "    for i in range(0,NEXT_STATES):\n",
    "        if next_states[i] == goal_state:\n",
    "            next_states_reward[i]=10\n",
    "        else:\n",
    "            next_states_reward[i]=0\n",
    "    return next_states_reward  \n",
    "\n",
    "def getSingleStateReward( action, next_state):\n",
    "    next_state_reward =0\n",
    "    \n",
    "    if next_state == goal_state:\n",
    "        next_state_reward=10\n",
    "    else:\n",
    "        next_state_reward=0\n",
    "\n",
    "    return next_state_reward   \n",
    "\n",
    "def StateTransition(current_state, action, next_state):\n",
    "    #next_state = getNextState( current_state, action) \n",
    "    if current_state == next_state:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0.7\n",
    "\n",
    "# Might need it.\n",
    "def weighted_choice(weights):\n",
    "    totals = []\n",
    "    running_total = 0\n",
    "\n",
    "    for w in weights:\n",
    "        running_total += w\n",
    "        totals.append(running_total)\n",
    "\n",
    "    rnd = random.random() * running_total\n",
    "    for i, total in enumerate(totals):\n",
    "        if rnd < total:\n",
    "            return i     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Policy Evaluation Algo\n",
    "def PolicyEvaluation(P,R,V,π,γ):\n",
    "    Δ=0\n",
    "    θ=2\n",
    "    while Δ<θ:\n",
    "        for s in range (0, STATES):\n",
    "            v=V[s]\n",
    "            for a in range (0, ACTIONS):\n",
    "                for n in range (0, NEXT_STATES):\n",
    "                    V[s]+=π[s][a]*P[s][a][n] * (R[s][a][n]+ γ*V[n])\n",
    "                    Δ=max(Δ, abs(v-V[s]))\n",
    "        return V\n",
    "    \n",
    "# Policy Iteration Algo\n",
    "def PolicyImprovement(P,R,V,π,γ):\n",
    "    policy_stable=True\n",
    "    for s in range (0, STATES):\n",
    "        for a in range (0, ACTIONS):\n",
    "            b=π[s][a]\n",
    "            temp=[0 for x in range(NEXT_STATES)]\n",
    "            for n in range (0, NEXT_STATES):\n",
    "                temp[n]+=P[s][a][n] * (R[s][a][n]+ γ*V[n])\n",
    "                #np.argmax()\n",
    "            max_index_action= np.argmax(temp)      \n",
    "            π[s][a]= temp[max_index_action]\n",
    "            if b!=π[s][a]:\n",
    "                policy_stable=False\n",
    "    return policy_stable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define P and R and N matrices.\n",
    "\n",
    "R = [[[0 for z in range(NEXT_STATES)] for x in range(ACTIONS)] for y in range(STATES)]  # Reward\n",
    "N = [[[0 for z in range(NEXT_STATES)] for x in range(ACTIONS)] for y in range(STATES)]  # Next State\n",
    "P = [[[0 for z in range(NEXT_STATES)] for x in range(ACTIONS)] for y in range(STATES)]  # Probabilty_new\n",
    "\n",
    "# Initialize P, R and N\n",
    "for i in range (0, STATES):\n",
    "    for j in range (0, ACTIONS):\n",
    "        current_state = S[i]\n",
    "        action = A[j]\n",
    "        next_states = getPossibleStates(current_state, action)\n",
    "        N[i][j] = next_states\n",
    "        P[i][j] = AllStatesTransition(current_state, action)\n",
    "        R[i][j] = getReward( action, next_states)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7 [[0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0], [1.0, 1.0, 1.0, 7.0], [0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0], [7.0, 1.0, 1.0, 1.0], [7.0, 7.0, 7.0, 7.0]] \n",
      "\n",
      " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.5, 0.0, 0.0, 0.0, 0.0, 0.0, 2.5, 10.0] \n",
      " False \n",
      "\n",
      "0.7 [[0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0], [1.0, 1.0, 1.0, 7.0], [0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0], [7.0, 1.0, 1.0, 1.0], [7.0, 7.0, 7.0, 7.0]] \n",
      "\n",
      " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 54.49999999999999, 0.0, 0.0, 0.0, 0.0, 0.0, 54.49999999999999, 290.0] \n",
      " True \n",
      "\n",
      "0.7 [[0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0], [1.0, 1.0, 1.0, 7.0], [0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0], [7.0, 1.0, 1.0, 1.0], [7.0, 7.0, 7.0, 7.0]] \n",
      "\n",
      " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 54.49999999999999, 0.0, 0.0, 0.0, 0.0, 0.0, 54.49999999999999, 290.0] \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 54.49999999999999,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 54.49999999999999,\n",
       " 290.0]"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize V(s)=0 and Q\n",
    "V = [0 for x in range(STATES)] \n",
    "Q = [[0 for x in range(ACTIONS)] for y in range(STATES)] \n",
    "\n",
    "# Initialize π(s,α)=0.25\n",
    "π = [[0.25 for x in range(ACTIONS)] for y in range(STATES)]  \n",
    "\n",
    "# change gamma\n",
    "γ=0.7\n",
    "\n",
    "stability=True\n",
    "total_reward_vf=0\n",
    "\n",
    "V=PolicyEvaluation(P,R,V,π,γ)\n",
    "stability=PolicyImprovement(P,R,V,π,γ)\n",
    "print(γ,π, \"\\n\\n\", V,\"\\n\", stability,\"\\n\")\n",
    "\n",
    "# for i in range (0,10):\n",
    "#     V=PolicyEvaluation(P,R,V,π,γ)\n",
    "#     stability=PolicyImprovement(P,R,V,π,γ)\n",
    "    \n",
    "# Policy Iteration Algo\n",
    "while stability == False:\n",
    "    V=PolicyEvaluation(P,R,V,π,γ)\n",
    "    stability=PolicyImprovement(P,R,V,π,γ)\n",
    "    print(γ,π, \"\\n\\n\", V,\"\\n\", stability,\"\\n\")\n",
    "    \n",
    "\n",
    "print(γ,π, \"\\n\\n\", V,\"\\n\")\n",
    "V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ε-greedy selection\n",
    "def selectActionGreedy(AS, AS_ind,Q, s_ind, step):   \n",
    "    \n",
    "    if step <= STEPS_GR:\n",
    "        max_ind=np.argmax(Q[s_ind])\n",
    "        AS[s_ind]=A[max_ind] \n",
    "        AS_ind[s_ind]=max_ind\n",
    "    else:\n",
    "        AS_ind[s_ind]=randint(0,3)\n",
    "        AS[s_ind]=A[AS_ind[s_ind]]\n",
    "\n",
    "    return AS[s_ind]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 6) 15 [[0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0], [0, 0.0, 0, 0], [0, 0.0, 0.0, 0], [0, 0.0, 0, 0.0], [0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0], [0, 0, 0, 0], [0.0, 0, 0, 0], [0, 0, 0, 0.0], [0, 0, 0, 0], [0, 0, 0, 0.0], [0.0, 0.0, 0.0, 0.0], [0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0], [0.0, 0, 0, 0], [0.0, 0.0, 0.0, 0.0], [0, 0, 0.0, 0.0], [0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 4.0], [0, 0.0, 0, 0], [0.0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0]]\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "# ε-greedy params\n",
    "ε=0.1\n",
    "STATES_GR = int (STATES *(1-ε))\n",
    "STATES_RAND=STATES-STATES_GR\n",
    "\n",
    "STEPS=100\n",
    "STEPS_GR = int (STEPS *(1-ε))\n",
    "STEPS_RAND=STEPS-STEPS_GR\n",
    "    \n",
    "# Initialize Q(s,a)=0\n",
    "Q = [[0 for x in range(ACTIONS)] for y in range(STATES)] \n",
    "\n",
    "#Learning rate\n",
    "α=0.4\n",
    "\n",
    "# Initialize array to hold the selected actions\n",
    "AS = [0 for x in range(STATES)]\n",
    "AS_ind = [0 for x in range(STATES)]\n",
    "\n",
    "total_reward=0  # Total reward initialization\n",
    "\n",
    "# Q-learning Algorithm\n",
    "for ep in range (0, 100):\n",
    "    s=starting_state\n",
    "    for step in range (0, STEPS):\n",
    "        s_ind=ConvertTupleToIndex(s)\n",
    "        a=selectActionGreedy(AS, AS_ind, Q, s_ind,step)\n",
    "        s_n=getNextState(s,a)\n",
    "        s_n_ind=ConvertTupleToIndex(s_n)\n",
    "        r=getSingleStateReward(a,s_n)\n",
    "        Q[s_ind][AS_ind[s_ind]]+=α*(r+γ*max(Q[s_n_ind])-Q[s_ind][AS_ind[s_ind]])\n",
    "        s=s_n\n",
    "        total_reward+=r # Accumulate Reward\n",
    "    if s==goal_state:\n",
    "        break   \n",
    "\n",
    "print(s, ep, Q)  \n",
    "print(total_reward)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX8AAAEACAYAAABbMHZzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAEOBJREFUeJzt3GusHGd9x/HvL9im5uJg6IkjSLCpUEOalgIvUmhUsSoY\nAqhJqlYRUVUlJbwqFFQQwgFV8ZtKBalCSC0vKg6RheBwLcQgaEyUbKtWKhhBlDQXk6q1GwI5nHKJ\nRIkgwL8vZhzWzrFDvHOyu+f5fqTVzDw7l/+Od3/n2Wd2nKpCktSWs2ZdgCTpiWf4S1KDDH9JapDh\nL0kNMvwlqUGGvyQ1aMsQO0lyFHgQ+DnwcFVdnGQn8HFgN3AUuLKqHhzieJKk6QzV8/85MKqqF1fV\nxX3bPuDmqroAuAW4bqBjSZKmNFT4Z519XQ4c6OcPAFcMdCxJ0pSGCv8CvpTkcJI39m27qmoVoKoe\nAM4Z6FiSpCkNMuYPXFJV306yBBxKcoTuD8Ik/x8JSZoTg4R/VX27n64l+SxwMbCaZFdVrSY5F/jO\netsm8Y+CJJ2BqsqZbjv1sE+SpyR5Wj//VOBVwB3AQeCafrWrgRtPtY+qWtjH9ddfP/MarH/2dbRY\n/yLXvhnqn9YQPf9dwGf6HvwW4CNVdSjJV4FPJHkDcAy4coBjSZIGMHX4V9V/Ay9ap/17wCun3b8k\naXje4Tul0Wg06xKmYv2ztcj1L3LtsPj1TytDjB1NVUBSs65BkhZNEmqWF3wlSYvH8JekBhn+ktQg\nw1+SGmT4S1KDDH9JapDhL0kNMvwlqUGGvyQ1yPCXpAYZ/pLUIMNfkhpk+EtSgwx/SWqQ4S9JDTL8\nJalBhr8kNcjwl6QGGf6S1CDDX5IaZPhLUoMMf0lqkOEvSQ0y/CWpQYa/JDXI8JekBg0W/knOSvK1\nJAf75Z1JDiU5kuSmJGcPdSxJ0nSG7Pm/FbhrYnkfcHNVXQDcAlw34LEkSVMYJPyTnAe8FvjgRPPl\nwIF+/gBwxRDH0nxZW4PDh7upNK98nz7aUD3/9wHvAGqibVdVrQJU1QPAOQMdS3NiZQV274a9e7vp\nysqsK5Iezffp+lJVj73W6XaQvA54TVW9OckIeFtVXZbk+1W1c2K971bVs9bZvqatQU+8tbXug/TQ\nQ79o274djh2DpaXZ1SVN2szv0yRUVc50+y0D1HAJcFmS1wLbgacn+TDwQJJdVbWa5FzgO6fawf79\n+x+ZH41GjEajAcrSRjp6FLZtO/FDtXVr177oHyptHpvpfToejxmPx4Ptb+qe/wk7S14OvL3v+b8X\n+G5VvSfJO4GdVbVvnW3s+S+gzdyj0uaxmd+n0/b8N/J3/n8D7E1yBHhFv6xNYmkJlpe7D9KOHd10\neXnxP1DaXHyfntqgPf8zKsCe/0JbW+u+Qu/Z4wdK82szvk+n7fkb/pK0gOZ52EeSNKcMf0lqkOEv\nSQ0y/CWpQYa/JDXI8JekBhn+ktQgw1+SGmT4S1KDDH9JapDhL0kNMvwlqUGGvyQ1yPCXpAYZ/pLU\nIMNfkhpk+EtSgwx/SWqQ4S9JDTL8JalBhr8kNcjwl6QGGf6S1CDDX5IaZPhLUoMMf0lqkOEvSQ0y\n/CWpQVOHf5InJ/lykq8nuSPJ9X37ziSHkhxJclOSs6cvV5I0hFTV9DtJnlJVP0ryJODfgLcAfwR8\nt6rem+SdwM6q2rfOtjVEDZLUkiRUVc50+0GGfarqR/3sk4EtQAGXAwf69gPAFUMcS5I0vUHCP8lZ\nSb4OPAB8qaoOA7uqahWgqh4AzhniWJKk6W0ZYidV9XPgxUl2AJ9JchFd7/+E1U61/f79+x+ZH41G\njEajIcqSpE1jPB4zHo8H298gY/4n7DD5K+BHwBuBUVWtJjkXuLWqLlxnfcf8JelxmvmYf5JfPf5L\nniTbgb3A3cBB4Jp+tauBG6c9liRpGFP3/JP8Ft0F3bP6x8er6q+TPBP4BHA+cAy4sqp+sM729vwl\n6XGatuc/+LDP4y7A8Jekx23mwz6SpMVj+EtSgwx/SWqQ4S9JDTL8JalBhr8kNcjwl6QGGf6S1CDD\nX5IaZPhLUoMMf0lqkOEvSQ0y/CWpQYa/JDXI8JekBhn+ktQgw1+SGmT4S1KDDH9JapDhL0kNMvwl\nqUGGvyQ1yPCXpAYZ/pLUIMNfkhpk+EtSgwx/SWqQ4S9JDZo6/JOcl+SWJHcmuSPJW/r2nUkOJTmS\n5KYkZ09friRpCEP0/H8KvK2qLgJeBrwpyQuAfcDNVXUBcAtw3QDHknQaa2tw+HA31aN5fn5h6vCv\nqgeq6rZ+/ofA3cB5wOXAgX61A8AV0x5L0qmtrMDu3bB3bzddWZl1RfPF83OiVNVwO0v2AGPgN4H7\nqmrnxHPfq6pnrrNNDVmD1KK1tS7QHnroF23bt8OxY7C0NLu65sVmPD9JqKqc6fZbBizkacCngLdW\n1Q+TnJzop0z4/fv3PzI/Go0YjUZDlSU14ehR2LbtxHDburVrX9RwG9JmOD/j8ZjxeDzY/gbp+SfZ\nAnwe+GJVvb9vuxsYVdVqknOBW6vqwnW2tecvTWkz9myHtBnPz7Q9/6F+6vkh4K7jwd87CFzTz18N\n3DjQsSSdZGkJlpe7QNuxo5suLy9usA3N8/NoU/f8k1wC/AtwB93QTgHvAr4CfAI4HzgGXFlVP1hn\ne3v+0kDW1rqhjD172g62U9lM52fanv+gF3zPqADDX5Iet3kZ9pEkLRDDX5IaZPhLUoMMf0lqkOEv\nSQ0y/CWpQYa/JDXI8JekBhn+ktQgw1+SGmT4S1KDDH9JapDhL0kNMvwlqUGGvyQ1yPCXpAYZ/pLU\nIMNfkhpk+EtSgwx/SWqQ4S9JDTL8JalBhr8kNcjwl6QGGf5DW1uDw4e7qSTNKcN/SCsrsHs37N3b\nTVdWZl2RJK0rVTXbApKadQ2DWFvrAv+hh37Rtn07HDsGS0uzq0vSppSEqsqZbm/PfyhHj8K2bSe2\nbd3atUvSnBkk/JMsJ1lNcvtE284kh5IcSXJTkrOHONbc2rMHfvKTE9sefrhrl6Q5M1TP/wbg1Se1\n7QNurqoLgFuA6wY61nxaWoLl5W6oZ8eObrq8vKmGfFq7lt3a61VbBhvzT7Ib+FxVvbBfvgd4eVWt\nJjkXGFfVC9bZbnOM+R+3ttYN9ezZs6mCf2UFrr22G9n6yU+6v2tXXTXrqjZOa69Xi2faMf+NDP/v\nVdUzJ54/YXmifXOF/ybU2rXs1l6vFtO04b9lyGIewykTfv/+/Y/Mj0YjRqPRE1COflnHr2VPhuHx\na9mbMQxbe71aDOPxmPF4PNj+NrLnfzcwmhj2ubWqLlxnO3v+c661nnBrr1eLaZ5+6pn+cdxB4Jp+\n/mrgxgGPpSdQA9eyT9Da61WbBun5J/koMAKeBawC1wOfBT4JnA8cA66sqh+ss609/wWxSa9ln1Jr\nr1eLZW4u+J5xAYa/JD1u8zTsI0laEIa/JDXI8JekBhn+ktQgw1+SGmT4S1KDDH9JapDhL0kNMvwl\nqUGGvyQ1yPCXpAYZ/pLUIMNfkhpk+EtSgwx/SWqQ4S9JDTL8JalBhr8kNcjwl6QGGf6S1CDDX5Ia\nZPhLUoMMf0lqkOEvSQ0y/CWpQYa/JDXI8JekBhn+ktSgDQ//JJcmuSfJN5K8c6OPJ0l6bKmqjdt5\nchbwDeAVwLeAw8Drq+qeiXVqI2uQpM0oCVWVM91+o3v+FwP3VtWxqnoY+Bhw+QYfU5LWtbYGhw93\n09ZtdPg/B7hvYvmbfZskPaFWVmD3bti7t5uurMy6otnygq+kTW9tDa69Fh56CB58sJtee23b3wC2\nbPD+7weeO7F8Xt92gv379z8yPxqNGI1GG1yWpJYcPQrbtnWhf9zWrV370tKsqnp8xuMx4/F4sP1t\n9AXfJwFH6C74fhv4CnBVVd09sY4XfCVtqLW1bqhnMvy3b4djxxYn/E821xd8q+pnwJuBQ8CdwMcm\ng1+SnghLS7C83AX+jh3ddHl5cYN/CBva8/+lCrDnL+kJsrbWDfXs2bP4wT9tz9/wl6QFNNfDPpKk\n+WT4S1KDDH9JapDhL0kNMvwlqUGGvyQ1yPCXpAYZ/pLUIMNfkhpk+EtSgwx/SWqQ4S9JDTL8JalB\nhr8kNcjwl6QGGf6S1CDDX5IaZPhLUoMMf0lqkOEvSQ0y/CWpQYa/JDXI8JekBhn+ktQgw1+SGmT4\nS1KDDH9JatBU4Z/kj5P8R5KfJXnJSc9dl+TeJHcnedV0ZUqShjRtz/8O4A+Bf55sTHIhcCVwIfAa\n4ANJMuWx5tJ4PJ51CVOx/tla5PoXuXZY/PqnNVX4V9WRqroXODnYLwc+VlU/raqjwL3AxdMca14t\n+hvI+mdrketf5Nph8euf1kaN+T8HuG9i+f6+TZI0B7Y81gpJvgTsmmwCCnh3VX1uowqTJG2cVNX0\nO0luBd5eVV/rl/cBVVXv6Zf/Cbi+qr68zrbTFyBJDaqqM76W+pg9/8dhsoiDwEeSvI9uuOf5wFfW\n22ia4iVJZ2ban3pekeQ+4KXA55N8EaCq7gI+AdwFfAH48xriK4YkaRCDDPtIkhbLzO7wTfLe/gaw\n25J8OsmOiecW4gaxJJcmuSfJN5K8c9b1nE6S85LckuTOJHckeUvfvjPJoSRHktyU5OxZ13o6Sc5K\n8rUkB/vlhak/ydlJPtm/r+9M8jsLVv9f9jd13p7kI0m2zXP9SZaTrCa5faLtlPXOW+6cov7BcnOW\n/73DIeCiqnoR3X0A1wEk+Q0W4AaxJGcBfwe8GrgIuCrJC2Zb1Wn9FHhbVV0EvAx4U1/vPuDmqroA\nuIX+32GOvZVuOPG4Rar//cAXqupC4LeBe1iQ+pM8G/gL4CVV9UK664VXMd/130D3+Zy0br1zmjvr\n1T9Ybs4s/Kvq5qr6eb/478B5/fxlLMYNYhcD91bVsap6GPgY3c1tc6mqHqiq2/r5HwJ3053zy4ED\n/WoHgCtmU+FjS3Ie8FrggxPNC1F/30P7vaq6AaB/fz/IgtTfexLw1CRbgO109+/Mbf1V9a/A909q\nPlW9c5c769U/ZG7Oy3/s9ga6C8OwODeInVznN5nPOh8lyR7gRXRvnl1VtQrdHwjgnNlV9pjeB7yD\n7j6T4xal/ucB/5vkhn7Y6h+SPIUFqb+qvgX8LfA/dJ/JB6vqZhak/gnnnKLeRcmdSVPl5oaGf5Iv\n9eODxx939NM/mFjn3cDDVbWykbWok+RpwKeAt/bfAE6+4j+XvwBI8jpgtf/2crqvs3NZP90wyUuA\nv6+qlwD/RzcEsSjn/xl0vebdwLPpvgH8CQtS/2ksWr3AMLk55O/8H6Wq9p7u+STX0H2N//2J5vuB\n8yeWz+vb5s39wHMnlue1zkf0X9c/BXy4qm7sm1eT7Kqq1STnAt+ZXYWndQlwWZLX0g05PD3Jh4EH\nFqT+bwL3VdVX++VP04X/opz/VwL/VVXfA0jyGeB3WZz6jztVvYuSO4Pl5ix/7XMp3Vf4y6rqxxNP\nHQRe3/+S4Hmc5gaxGTsMPD/J7iTbgNfT1T7PPgTcVVXvn2g7CFzTz18N3HjyRvOgqt5VVc+tql+j\nO9e3VNWfAp9jMepfBe5L8ut90yuAO1mQ80833PPSJL/SX0h8Bd2F93mvPzz6BtRr+vnJeuc1d06o\nf9DcrKqZPOguSBwDvtY/PjDx3HXAf9JdlHzVrGr8JV7DpcCR/rXsm3U9j1HrJcDPgNuAr/fn/FLg\nmcDN/es4BDxj1rX+Eq/l5cDBfn5h6qf7hc/h/t/gH4GzF6z+6/vP5O10F0u3znP9wEeBbwE/pvvj\n9WfAzlPVO2+5c4r6B8tNb/KSpAbNy699JElPIMNfkhpk+EtSgwx/SWqQ4S9JDTL8JalBhr8kNcjw\nl6QG/T9YgXHZMr+pIQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x110fe8390>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_result(X1,X2,Y1,Y2):\n",
    "    _ = plt.scatter(x=X1, y=X2, color='b')\n",
    "    _ = plt.scatter(x=Y1, y=Y2, color='r')\n",
    "    \n",
    "X1=[69, 98, 25, 99, 99, 50, 27]\n",
    "X2=[20, 40, 10,  0, 20, 10, 40]\n",
    "Y1=[2]\n",
    "Y2=[400/35]\n",
    "plot_result(X1,X2,Y1,Y2)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
